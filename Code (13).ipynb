{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b284f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:54] Loading data…\n",
      "[20:23:54] Loaded Train: (125973, 43) | Test: (22544, 43)\n",
      "[20:23:54] Encoding categorical columns…\n",
      "[20:23:54] FAST mode ON → subsampling 25% stratified…\n",
      "[20:23:54] New Train: (31493, 38) | New Test: (5636, 38)\n",
      "[20:23:54] Scaling features…\n",
      "[20:23:54] Setting up models…\n",
      "[20:23:55] Training & evaluating models…\n",
      "[20:23:55] → Fitting: HistGradBoost (FAST) …\n",
      "[20:23:55]    fit done in 0.54s — scoring…\n",
      "[20:23:55]    HistGradBoost (FAST) — Acc:0.843 | F1_w:0.843 | AUC:0.980\n",
      "[20:23:55] → Fitting: RandomForest (small) …\n",
      "[20:23:56]    fit done in 0.53s — scoring…\n",
      "[20:23:56]    RandomForest (small) — Acc:0.816 | F1_w:0.815 | AUC:0.983\n",
      "[20:23:56] → Fitting: Logistic Reg. …\n",
      "[20:23:57]    fit done in 1.33s — scoring…\n",
      "[20:23:57]    Logistic Reg. — Acc:0.836 | F1_w:0.836 | AUC:0.924\n",
      "[20:23:57] Saved log → Data/run_log_20251027_202355.json\n",
      "[20:23:57] Leaderboard (Test):\n",
      "                Model     Acc  Prec_w   Rec_w    F1_w  ROC_AUC  Fit(s)\n",
      " HistGradBoost (FAST)  0.8426  0.8731  0.8426  0.8427   0.9799    0.54\n",
      "        Logistic Reg.  0.8359  0.8552  0.8359  0.8365   0.9237    1.33\n",
      " RandomForest (small)  0.8158  0.8579  0.8158  0.8152   0.9828    0.53\n",
      "[20:23:57] Plotting confusion matrices…\n",
      "[20:23:58] Plotting ROC curves…\n",
      "[20:23:58] Plotting feature importance…\n",
      "[20:23:58] Done. Figures in Data/figs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, time, json, sys, warnings, gc\n",
    "warnings.filterwarnings(\"ignore\", message=\".*glibc.*\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, roc_auc_score, average_precision_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# ---- SETTINGS: flip these for speed/quality trade-offs ----\n",
    "FAST = True             # True = much faster; False = full\n",
    "FAST_FRAC = 0.25        # use 25% of train/test (stratified) when FAST\n",
    "MAKE_HEAVY_PLOTS = not FAST  # skip heavy plots in FAST\n",
    "TOPK_IMPORTANCE = 12 if FAST else 20\n",
    "\n",
    "def status(msg):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "# ---- Paths ----\n",
    "OUTDIR = \"Data\"\n",
    "FIGDIR = os.path.join(OUTDIR, \"figs\")\n",
    "os.makedirs(FIGDIR, exist_ok=True)\n",
    "TRAIN_PATH = os.path.join(OUTDIR, \"Train.txt\")\n",
    "TEST_PATH  = os.path.join(OUTDIR, \"Test.txt\")\n",
    "\n",
    "# ---- Load ----\n",
    "status(\"Loading data…\")\n",
    "COLS = [\"duration\",\"protocoltype\",\"service\",\"flag\",\"srcbytes\",\"dstbytes\",\"land\",\"wrongfragment\",\"urgent\",\"hot\",\n",
    "        \"numfailedlogins\",\"loggedin\",\"numcompromised\",\"rootshell\",\"suattempted\",\"numroot\",\"numfilecreations\",\n",
    "        \"numshells\",\"numaccessfiles\",\"numoutboundcmds\",\"ishostlogin\",\"isguestlogin\",\"count\",\"srvcount\",\"serrorrate\",\n",
    "        \"srvserrorrate\",\"rerrorrate\",\"srvrerrorrate\",\"samesrvrate\",\"diffsrvrate\",\"srvdiffhostrate\",\"dsthostcount\",\n",
    "        \"dsthostsrvcount\",\"dsthostsamesrvrate\",\"dsthostdiffsrvrate\",\"dsthostsamesrcportrate\",\"dsthostsrvdiffhostrate\",\n",
    "        \"dsthostserrorrate\",\"dsthostsrvserrorrate\",\"dsthostrerrorrate\",\"dsthostsrvrerrorrate\",\"attack\",\"lastflag\"]\n",
    "DROP_COLS = [\"land\",\"urgent\",\"numfailedlogins\",\"numoutboundcmds\"]\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH, sep=\",\", names=COLS)\n",
    "test_df  = pd.read_csv(TEST_PATH,  sep=\",\", names=COLS)\n",
    "status(f\"Loaded Train: {train_df.shape} | Test: {test_df.shape}\")\n",
    "\n",
    "# ---- Prep ----\n",
    "def to_binary(df):\n",
    "    df = df.copy()\n",
    "    df[\"attack\"] = np.where(df[\"attack\"]==\"normal\", \"normal\", \"attack\")\n",
    "    return df\n",
    "\n",
    "train_df = to_binary(train_df)\n",
    "test_df  = to_binary(test_df)\n",
    "\n",
    "for c in DROP_COLS:\n",
    "    if c in train_df: train_df.drop(columns=c, inplace=True)\n",
    "    if c in test_df:  test_df.drop(columns=c, inplace=True)\n",
    "\n",
    "# Label encoders fit on combined to avoid unseen categories crash\n",
    "status(\"Encoding categorical columns…\")\n",
    "LE_protocol = LabelEncoder()\n",
    "LE_service  = LabelEncoder()\n",
    "LE_flag     = LabelEncoder()\n",
    "LE_attack   = LabelEncoder()\n",
    "\n",
    "proto_all  = pd.concat([train_df[\"protocoltype\"], test_df[\"protocoltype\"]], axis=0)\n",
    "serv_all   = pd.concat([train_df[\"service\"],      test_df[\"service\"]],      axis=0)\n",
    "flag_all   = pd.concat([train_df[\"flag\"],         test_df[\"flag\"]],         axis=0)\n",
    "attack_all = pd.concat([train_df[\"attack\"],       test_df[\"attack\"]],       axis=0)\n",
    "\n",
    "LE_protocol.fit(proto_all)\n",
    "LE_service.fit(serv_all)\n",
    "LE_flag.fit(flag_all)\n",
    "LE_attack.fit(attack_all)\n",
    "\n",
    "for df in (train_df, test_df):\n",
    "    df[\"protocoltype\"] = LE_protocol.transform(df[\"protocoltype\"])\n",
    "    df[\"service\"]      = LE_service.transform(df[\"service\"])\n",
    "    df[\"flag\"]         = LE_flag.transform(df[\"flag\"])\n",
    "    df[\"attack\"]       = LE_attack.transform(df[\"attack\"]).astype(int)\n",
    "\n",
    "X_train = train_df.drop(columns=[\"attack\"])\n",
    "y_train = train_df[\"attack\"]\n",
    "X_test  = test_df.drop(columns=[\"attack\"])\n",
    "y_test  = test_df[\"attack\"]\n",
    "\n",
    "# ---- FAST subsample (stratified) ----\n",
    "if FAST:\n",
    "    status(f\"FAST mode ON → subsampling {int(FAST_FRAC*100)}% stratified…\")\n",
    "    def strat_subsample(X, y, frac):\n",
    "        if frac >= 1.0: return X, y\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=1-frac, random_state=42)\n",
    "        idx_keep, _ = next(sss.split(X, y))\n",
    "        return X.iloc[idx_keep], y.iloc[idx_keep]\n",
    "    X_train, y_train = strat_subsample(X_train, y_train, FAST_FRAC)\n",
    "    X_test,  y_test  = strat_subsample(X_test,  y_test,  FAST_FRAC)\n",
    "    status(f\"New Train: {X_train.shape} | New Test: {X_test.shape}\")\n",
    "\n",
    "# ---- Scale ----\n",
    "status(\"Scaling features…\")\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xtr = scaler.transform(X_train)\n",
    "Xte = scaler.transform(X_test)\n",
    "\n",
    "# ---- Models (trimmed & fast) ----\n",
    "status(\"Setting up models…\")\n",
    "models = {\n",
    "    \"HistGradBoost (FAST)\": HistGradientBoostingClassifier(\n",
    "        max_iter=150 if FAST else 300,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"RandomForest (small)\": RandomForestClassifier(\n",
    "        n_estimators=200 if FAST else 400,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Logistic Reg.\": LogisticRegression(max_iter=400, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Optional XGBoost with early stopping (kept small)\n",
    "if \"XGBoost\" in name:\n",
    "    # early stopping with a small valid set from train to keep it fast\n",
    "    split = int(0.85 * len(Xtr))\n",
    "    Xtr_fit, ytr_fit = Xtr[:split], y_train.iloc[:split]\n",
    "    Xval,    yval    = Xtr[split:], y_train.iloc[split:]\n",
    "\n",
    "    try:\n",
    "        import inspect\n",
    "        if \"early_stopping_rounds\" in inspect.signature(model.fit).parameters:\n",
    "            # Older/compatible API\n",
    "            model.fit(\n",
    "                Xtr_fit, ytr_fit,\n",
    "                eval_set=[(Xval, yval)],\n",
    "                early_stopping_rounds=20,\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            # Newer API: use callbacks\n",
    "            from xgboost.callback import EarlyStopping\n",
    "            model.fit(\n",
    "                Xtr_fit, ytr_fit,\n",
    "                eval_set=[(Xval, yval)],\n",
    "                callbacks=[EarlyStopping(rounds=20, save_best=True, maximize=False)],\n",
    "                verbose=False\n",
    "            )\n",
    "    except TypeError:\n",
    "        # Last-resort fallback: no early stopping, fewer trees to stay FAST\n",
    "        model.set_params(n_estimators=min(model.get_params().get(\"n_estimators\", 250), 200))\n",
    "        model.fit(Xtr_fit, ytr_fit, verbose=False)\n",
    "\n",
    "# ---- Train/Eval helpers ----\n",
    "def eval_scores(y_true, y_pred, y_score):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    rec = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "    f1  = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    roc = roc_auc_score(y_true, y_score) if y_score is not None else np.nan\n",
    "    ap  = average_precision_score(y_true, y_score) if y_score is not None else np.nan\n",
    "    return acc, pre, rec, f1, roc, ap\n",
    "\n",
    "# ---- Run ----\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_log = {\"run_tag\": RUN_TAG, \"env\": {\"python\": sys.version}, \"FAST\": FAST, \"models\": {}}\n",
    "cms, curves = {}, {}\n",
    "\n",
    "status(\"Training & evaluating models…\")\n",
    "for name, model in models.items():\n",
    "    status(f\"→ Fitting: {name} …\")\n",
    "    t0 = time.time()\n",
    "    if \"XGBoost\" in name:\n",
    "        # early stopping with a small valid set from train to keep it fast\n",
    "        split = int(0.85 * len(Xtr))\n",
    "        Xtr_fit, ytr_fit = Xtr[:split], y_train.iloc[:split]\n",
    "        Xval,    yval    = Xtr[split:], y_train.iloc[split:]\n",
    "        model.fit(Xtr_fit, ytr_fit, eval_set=[(Xval, yval)], verbose=False, early_stopping_rounds=20)\n",
    "    else:\n",
    "        model.fit(Xtr, y_train)\n",
    "    fit_s = time.time() - t0\n",
    "    status(f\"   fit done in {fit_s:.2f}s — scoring…\")\n",
    "\n",
    "    y_pred = model.predict(Xte)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(Xte)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_score = model.decision_function(Xte)\n",
    "    else:\n",
    "        y_score = None\n",
    "\n",
    "    acc, pre, rec, f1, roc, ap = eval_scores(y_test, y_pred, y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    cms[name] = (tn, fp, fn, tp)\n",
    "\n",
    "    if y_score is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        curves[name] = (fpr, tpr, roc)\n",
    "\n",
    "    run_log[\"models\"][name] = {\n",
    "        \"fit_seconds\": round(fit_s, 2),\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": round(acc, 4),\n",
    "            \"precision_weighted\": round(pre, 4),\n",
    "            \"recall_weighted\": round(rec, 4),\n",
    "            \"f1_weighted\": round(f1, 4),\n",
    "            \"roc_auc\": round(float(roc), 4) if not np.isnan(roc) else None,\n",
    "            \"avg_precision\": round(float(ap), 4) if not np.isnan(ap) else None,\n",
    "        },\n",
    "        \"confusion_matrix\": {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)},\n",
    "    }\n",
    "    status(f\"   {name} — Acc:{acc:.3f} | F1_w:{f1:.3f} | AUC:{(roc if not np.isnan(roc) else float('nan')):.3f}\")\n",
    "\n",
    "# ---- Save log ----\n",
    "log_path = os.path.join(OUTDIR, f\"run_log_{RUN_TAG}.json\")\n",
    "with open(log_path, \"w\") as f:\n",
    "    json.dump(run_log, f, indent=2)\n",
    "status(f\"Saved log → {log_path}\")\n",
    "\n",
    "# ---- Quick leaderboard print ----\n",
    "rows = []\n",
    "for name, rec in run_log[\"models\"].items():\n",
    "    m = rec[\"metrics\"]\n",
    "    rows.append([name, m[\"accuracy\"], m[\"precision_weighted\"], m[\"recall_weighted\"], m[\"f1_weighted\"], m[\"roc_auc\"], rec[\"fit_seconds\"]])\n",
    "tbl = pd.DataFrame(rows, columns=[\"Model\",\"Acc\",\"Prec_w\",\"Rec_w\",\"F1_w\",\"ROC_AUC\",\"Fit(s)\"]).sort_values(\"F1_w\", ascending=False)\n",
    "status(\"Leaderboard (Test):\")\n",
    "print(tbl.to_string(index=False))\n",
    "\n",
    "# ---- Minimal plots in FAST; full only if MAKE_HEAVY_PLOTS ----\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": \"#0b1020\",\n",
    "    \"axes.facecolor\": \"#0b1020\",\n",
    "    \"axes.labelcolor\": \"#e9ecf1\",\n",
    "    \"text.color\": \"#e9ecf1\",\n",
    "    \"xtick.color\": \"#8b93a6\",\n",
    "    \"ytick.color\": \"#8b93a6\",\n",
    "    \"grid.color\": \"#2a3346\",\n",
    "    \"grid.alpha\": 0.35,\n",
    "    \"axes.grid\": True,\n",
    "})\n",
    "\n",
    "def savefig(path):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# Confusion matrices (small grid)\n",
    "status(\"Plotting confusion matrices…\")\n",
    "n = len(cms)\n",
    "ncols = 2 if FAST else 3\n",
    "nrows = (n + ncols - 1) // ncols\n",
    "plt.figure(figsize=(6*ncols, 3.7*nrows))\n",
    "for i, (name, (tn, fp, fn, tp)) in enumerate(cms.items(), 1):\n",
    "    plt.subplot(nrows, ncols, i)\n",
    "    cm = np.array([[tn, fp],[fn, tp]])\n",
    "    im = plt.imshow(cm, cmap=\"magma\")\n",
    "    for (r,c), val in np.ndenumerate(cm):\n",
    "        plt.text(c, r, f\"{val:,}\", ha=\"center\", va=\"center\", color=\"#e9ecf1\")\n",
    "    plt.xticks([0,1], [\"Attack(0)\",\"Normal(1)\"], rotation=15)\n",
    "    plt.yticks([0,1], [\"Attack(0)\",\"Normal(1)\"])\n",
    "    plt.title(f\"{name}\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "savefig(os.path.join(FIGDIR, \"confusion_matrices_fast.png\"))\n",
    "\n",
    "# ROC (only if scores exist)\n",
    "if curves:\n",
    "    status(\"Plotting ROC curves…\")\n",
    "    plt.figure(figsize=(6.5,5.5))\n",
    "    for name, (fpr, tpr, aucv) in curves.items():\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC={aucv:.3f})\", linewidth=2)\n",
    "    plt.plot([0,1],[0,1],\"--\", color=\"#8b93a6\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC — Test\")\n",
    "    plt.legend(frameon=False, loc=\"lower right\")\n",
    "    savefig(os.path.join(FIGDIR, \"roc_curves_fast.png\"))\n",
    "\n",
    "# Feature importance (only for tree models with attr)\n",
    "status(\"Plotting feature importance…\")\n",
    "def plot_feature_importance(model, name, feature_names, topk=TOPK_IMPORTANCE):\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        imp = model.feature_importances_\n",
    "        idx = np.argsort(imp)[::-1][:topk]\n",
    "        plt.figure(figsize=(7,0.4*topk+2))\n",
    "        y = np.array(feature_names)[idx]\n",
    "        x = imp[idx]\n",
    "        plt.barh(y, x, color=\"#7c83ff\", edgecolor=\"black\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.xlabel(\"Importance\"); plt.title(f\"{name} — Top {topk}\")\n",
    "        savefig(os.path.join(FIGDIR, f\"featimp_{name.replace(' ','_')}.png\"))\n",
    "\n",
    "for name, mdl in models.items():\n",
    "    plot_feature_importance(mdl, name, X_train.columns, topk=TOPK_IMPORTANCE)\n",
    "\n",
    "status(f\"Done. Figures in {FIGDIR}\")\n",
    "gc.collect();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e83ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:28] Plotting improved confusion matrices with percentages…\n",
      "[20:26:28] Saved → Data/figs/confusion_matrices_pretty.png\n"
     ]
    }
   ],
   "source": [
    "# ===== Better Confusion Matrices (counts + row % with nicer colors) =====\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def _fmt_cm_annot(cm):\n",
    "    \"\"\"Return string annotations like '9,443\\n97.2%' for each cell.\"\"\"\n",
    "    cm = cm.astype(float)\n",
    "    row_sum = cm.sum(axis=1, keepdims=True)\n",
    "    row_sum[row_sum == 0] = 1.0\n",
    "    pct = cm / row_sum * 100.0\n",
    "    annot = np.empty_like(cm, dtype=object)\n",
    "    for r in range(cm.shape[0]):\n",
    "        for c in range(cm.shape[1]):\n",
    "            annot[r, c] = f\"{int(cm[r, c]):,}\\n{pct[r, c]:.1f}%\"\n",
    "    return annot, pct\n",
    "\n",
    "def plot_confusion_matrix_pretty(cm_counts, labels=(\"Attack(0)\", \"Normal(1)\"), title=\"Confusion Matrix\", save_path=None):\n",
    "    \"\"\"\n",
    "    cm_counts = [[tn, fp],\n",
    "                 [fn, tp]]\n",
    "    Shows counts + row-normalized percentages; colors by percentage.\n",
    "    \"\"\"\n",
    "    cm = np.array(cm_counts, dtype=float)\n",
    "    annot, pct = _fmt_cm_annot(cm)\n",
    "\n",
    "    plt.figure(figsize=(5.8, 4.6))\n",
    "    # good perceptual map; works on light/dark backgrounds\n",
    "    ax = sns.heatmap(\n",
    "        pct,                     # color by row %\n",
    "        annot=annot,             # show both values\n",
    "        fmt=\"\", \n",
    "        cmap=\"crest\",            # pleasant green/teal gradient\n",
    "        vmin=0, vmax=100,\n",
    "        cbar_kws={\"label\": \"Row %\"},\n",
    "        linewidths=0.5, linecolor=\"white\"\n",
    "    )\n",
    "    ax.set_xticklabels(labels, rotation=15)\n",
    "    ax.set_yticklabels(labels, rotation=0)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(title, pad=10)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=160, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# --- Use the counts we already stored in `cms` ---\n",
    "# `cms[name] = (tn, fp, fn, tp)` from your loop\n",
    "status(\"Plotting improved confusion matrices with percentages…\")\n",
    "n = len(cms)\n",
    "ncols = 2 if FAST else 3\n",
    "nrows = (n + ncols - 1) // ncols\n",
    "plt.figure(figsize=(6*ncols, 4.6*nrows))\n",
    "\n",
    "for i, (name, (tn, fp, fn, tp)) in enumerate(cms.items(), 1):\n",
    "    plt.subplot(nrows, ncols, i)\n",
    "    cm_counts = [[tn, fp],[fn, tp]]\n",
    "    annot, pct = _fmt_cm_annot(np.array(cm_counts))\n",
    "    sns.heatmap(\n",
    "        pct, annot=annot, fmt=\"\",\n",
    "        cmap=\"crest\", vmin=0, vmax=100,\n",
    "        cbar_kws={\"label\": \"Row %\"},\n",
    "        linewidths=0.5, linecolor=\"white\"\n",
    "    )\n",
    "    plt.xticks([0.5,1.5], [\"Attack(0)\",\"Normal(1)\"], rotation=15)\n",
    "    plt.yticks([0.5,1.5], [\"Attack(0)\",\"Normal(1)\"], rotation=0)\n",
    "    plt.title(name, pad=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(os.path.join(FIGDIR, \"confusion_matrices_pretty.png\"))\n",
    "status(\"Saved → \" + os.path.join(FIGDIR, \"confusion_matrices_pretty.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a71ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
